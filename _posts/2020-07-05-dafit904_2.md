---
title: Dafit904_2
category: Dafit
tag: [NLP, Python, Tokenizer]
---


## DF904. 한국어 데이터 Tokenizer

BERT와 같은 자연어 처리 모델을 사용하기 위한 전 단계의 과정이다. 
한국어 데이터를 가공하여 모델의 input으로 넣기 위해 필요한 과정을 문제로 담았다. 
형태소 분석기와 Wordpiece 모델을 사용하여 한국어 데이터를 토크나이징 하는 과정과 한국어 vocabulary를 만들고 token을 id로 바꾸어 보는 과정이 담겨있다. 


~~~
모든 문제의 저작권은 다핏(www.dafit.me)에 있습니다. 
~~~

### 1. 한국어 corpus 형태소 분석 

한국어 위키 데이터를 다운받아 정제하고, 각 문장에 대해 형태소 분석을 해보세요. 분석 결과는 아래와 같이 txt 파일로 저장합니다. 

ex) 
나/NP 는/JX 밥/NNG 을/JKO 먹/W 는다/EC
하늘/NNG 을/JKO 나/NP 는/JX 자동차/NNG


### 데이터셋 다운로드 

[위키백과: 데이터베이스 다운로드](https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4_%EB%8B%A4%EC%9A%B4%EB%A1%9C%EB%93%9C)


## Code

~~~
from konlpy.tag import Okt
import xml.etree.ElementTree as elemTree

tree = elemTree.parse('/Users/p1zz4/Downloads/kowiki-20200620-abstract.xml')
root = tree.getroot()

list_ab=[]

for abstract in root.iter("abstract"):
    list_ab.append(abstract.text)
    if len(list_ab) == 100:
        break
        
t = Okt()

with open("/Users/p1zz4/Downloads/DF904_02_감자.txt", mode = 'wb') as output:
    for content in list_ab:
        for morph in t.pos(content):
            data = morph[0]+'/'+morph[1]+' '
            data = data.encode("utf-8")
            output.write(data)
        output.write('\n'.encode("utf-8"))
~~~

## 출력 결과

![출력결과](https://i.imgur.com/MbaNCDQ.png)
