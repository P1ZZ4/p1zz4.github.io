---
title: Dafit904_3
category: Dafit
tag: [NLP, Python, Tokenizer]
---


## DF904. 한국어 데이터 Tokenizer

BERT와 같은 자연어 처리 모델을 사용하기 위한 전 단계의 과정이다. 
한국어 데이터를 가공하여 모델의 input으로 넣기 위해 필요한 과정을 문제로 담았다. 
형태소 분석기와 Wordpiece 모델을 사용하여 한국어 데이터를 토크나이징 하는 과정과 한국어 vocabulary를 만들고 token을 id로 바꾸어 보는 과정이 담겨있다. 


~~~
모든 문제의 저작권은 다핏(www.dafit.me)에 있습니다. 
~~~

### 3. token을 id로 

형태소 분석이 완료된 txt 파일을 열고, 모든 token에 대해서 각 token과 id를 mapping하는 vocab 딕셔너리를 생성합니다. 이후 모든 문장의 token을 id로 치환해 봅니다. 
추가적으로, 빈도수 순대로 단어를 정렬하여 id를 부여하는 작업을 해보시는 것도 좋은 훈련이 됩니다. 

ex) 형태소 태깅 후의 데이터: 나/NP 는/JX 밥/NNG 을/JKO 먹/VV 는다/EC
Vocab 딕셔너리: {‘밥/NNG’:0, ‘나/NP’:1, ‘는/JX’:2, ‘먹/VV’:3, ‘을/JKO’:4, ‘는다/EC’: 5}
